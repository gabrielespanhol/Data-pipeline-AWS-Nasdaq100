{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13dd713f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import awswrangler as wr\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9223d460",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabriel\\AppData\\Local\\Temp\\ipykernel_7956\\201727266.py:15: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(tickers, period='3mo')\n",
      "[*********************100%***********************]  101 of 101 completed\n"
     ]
    }
   ],
   "source": [
    "# nasdak_100\n",
    "tickers = [\n",
    "    \"ADBE\",\"AMD\",\"ABNB\",\"GOOGL\",\"GOOG\",\"AMZN\",\"AEP\",\"AMGN\",\"ADI\",\"AAPL\",\n",
    "    \"AMAT\",\"APP\",\"ARM\",\"ASML\",\"AZN\",\"TEAM\",\"ADSK\",\"ADP\",\"AXON\",\"BKR\",\n",
    "    \"BIIB\",\"BKNG\",\"AVGO\",\"CDNS\",\"CDW\",\"CHTR\",\"CTAS\",\"CSCO\",\"CCEP\",\"CTSH\",\n",
    "    \"CMCSA\",\"CEG\",\"CPRT\",\"CSGP\",\"COST\",\"CRWD\",\"CSX\",\"DDOG\",\"DXCM\",\"FANG\",\n",
    "    \"DASH\",\"EA\",\"EXC\",\"FAST\",\"FTNT\",\"GEHC\",\"GILD\",\"GFS\",\"HON\",\"IDXX\",\n",
    "    \"INTC\",\"INTU\",\"ISRG\",\"KDP\",\"KLAC\",\"KHC\",\"LRCX\",\"LIN\",\"LULU\",\"MAR\",\n",
    "    \"MRVL\",\"MELI\",\"META\",\"MCHP\",\"MU\",\"MSFT\",\"MSTR\",\"MDLZ\",\"MNST\",\"NFLX\",\n",
    "    \"NVDA\",\"NXPI\",\"ORLY\",\"ODFL\",\"ON\",\"PCAR\",\"PLTR\",\"PANW\",\"PAYX\",\"PYPL\",\n",
    "    \"PDD\",\"PEP\",\"QCOM\",\"REGN\",\"ROP\",\"ROST\",\"SHOP\",\"SBUX\",\"SNPS\",\"TMUS\",\n",
    "    \"TTWO\",\"TSLA\",\"TXN\",\"TRI\",\"TTD\",\"VRSK\",\"VRTX\",\"WBD\",\"WDAY\",\"XEL\",\"ZS\"\n",
    "]\n",
    "\n",
    "data = yf.download(tickers, period='3mo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50aa483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date Ticker        Open        High         Low       Close  \\\n",
      "0    2025-07-07   AAPL  212.438891  215.984870  208.563300  209.711990   \n",
      "1    2025-07-08   AAPL  209.861836  211.190315  208.213698  209.771927   \n",
      "2    2025-07-09   AAPL  209.292475  211.090437  206.985096  210.900650   \n",
      "3    2025-07-10   AAPL  210.271350  213.237984  209.791898  212.169205   \n",
      "4    2025-07-11   AAPL  210.331296  211.889525  209.622094  210.920624   \n",
      "...         ...    ...         ...         ...         ...         ...   \n",
      "6459 2025-09-29     ZS  297.109985  300.809998  293.510010  296.899994   \n",
      "6460 2025-09-30     ZS  295.839996  300.209991  291.570007  299.660004   \n",
      "6461 2025-10-01     ZS  298.609985  305.910004  297.135010  304.529999   \n",
      "6462 2025-10-02     ZS  306.000000  307.790009  302.149994  307.579987   \n",
      "6463 2025-10-03     ZS  308.070007  309.790009  301.709991  305.410004   \n",
      "\n",
      "        Volume  \n",
      "0     50229000  \n",
      "1     42848900  \n",
      "2     48749400  \n",
      "3     44443600  \n",
      "4     39765800  \n",
      "...        ...  \n",
      "6459   1418600  \n",
      "6460   1886200  \n",
      "6461   1921100  \n",
      "6462   1247400  \n",
      "6463    977600  \n",
      "\n",
      "[6464 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "df_reset = data.copy().reset_index()  # transforma 'Date' em coluna\n",
    "\n",
    "\n",
    "dfs = []\n",
    "for ticker in data.columns.levels[1]:  \n",
    "    temp = pd.DataFrame({\n",
    "        \"Date\": df_reset[\"Date\"],\n",
    "        \"Ticker\": ticker,\n",
    "        \"Open\": df_reset[(\"Open\", ticker)],\n",
    "        \"High\": df_reset[(\"High\", ticker)],\n",
    "        \"Low\": df_reset[(\"Low\", ticker)],\n",
    "        \"Close\": df_reset[(\"Close\", ticker)],\n",
    "        \"Volume\": df_reset[(\"Volume\", ticker)],\n",
    "    })\n",
    "    dfs.append(temp)\n",
    "\n",
    "df_final = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "df_final.to_parquet(\n",
    "    \"nasdaq_data_parquet\",\n",
    "    engine=\"pyarrow\",\n",
    "    partition_cols=[\"Date\"],\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5871a40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partição 2025/7/7 enviada em s3://dados-gabriel-espanhol/raw/2025/07/07/data.parquet\n",
      "Partição 2025/7/8 enviada em s3://dados-gabriel-espanhol/raw/2025/07/08/data.parquet\n",
      "Partição 2025/7/9 enviada em s3://dados-gabriel-espanhol/raw/2025/07/09/data.parquet\n",
      "Partição 2025/7/10 enviada em s3://dados-gabriel-espanhol/raw/2025/07/10/data.parquet\n",
      "Partição 2025/7/11 enviada em s3://dados-gabriel-espanhol/raw/2025/07/11/data.parquet\n",
      "Partição 2025/7/14 enviada em s3://dados-gabriel-espanhol/raw/2025/07/14/data.parquet\n",
      "Partição 2025/7/15 enviada em s3://dados-gabriel-espanhol/raw/2025/07/15/data.parquet\n",
      "Partição 2025/7/16 enviada em s3://dados-gabriel-espanhol/raw/2025/07/16/data.parquet\n",
      "Partição 2025/7/17 enviada em s3://dados-gabriel-espanhol/raw/2025/07/17/data.parquet\n",
      "Partição 2025/7/18 enviada em s3://dados-gabriel-espanhol/raw/2025/07/18/data.parquet\n",
      "Partição 2025/7/21 enviada em s3://dados-gabriel-espanhol/raw/2025/07/21/data.parquet\n",
      "Partição 2025/7/22 enviada em s3://dados-gabriel-espanhol/raw/2025/07/22/data.parquet\n",
      "Partição 2025/7/23 enviada em s3://dados-gabriel-espanhol/raw/2025/07/23/data.parquet\n",
      "Partição 2025/7/24 enviada em s3://dados-gabriel-espanhol/raw/2025/07/24/data.parquet\n",
      "Partição 2025/7/25 enviada em s3://dados-gabriel-espanhol/raw/2025/07/25/data.parquet\n",
      "Partição 2025/7/28 enviada em s3://dados-gabriel-espanhol/raw/2025/07/28/data.parquet\n",
      "Partição 2025/7/29 enviada em s3://dados-gabriel-espanhol/raw/2025/07/29/data.parquet\n",
      "Partição 2025/7/30 enviada em s3://dados-gabriel-espanhol/raw/2025/07/30/data.parquet\n",
      "Partição 2025/7/31 enviada em s3://dados-gabriel-espanhol/raw/2025/07/31/data.parquet\n",
      "Partição 2025/8/1 enviada em s3://dados-gabriel-espanhol/raw/2025/08/01/data.parquet\n",
      "Partição 2025/8/4 enviada em s3://dados-gabriel-espanhol/raw/2025/08/04/data.parquet\n",
      "Partição 2025/8/5 enviada em s3://dados-gabriel-espanhol/raw/2025/08/05/data.parquet\n",
      "Partição 2025/8/6 enviada em s3://dados-gabriel-espanhol/raw/2025/08/06/data.parquet\n",
      "Partição 2025/8/7 enviada em s3://dados-gabriel-espanhol/raw/2025/08/07/data.parquet\n",
      "Partição 2025/8/8 enviada em s3://dados-gabriel-espanhol/raw/2025/08/08/data.parquet\n",
      "Partição 2025/8/11 enviada em s3://dados-gabriel-espanhol/raw/2025/08/11/data.parquet\n",
      "Partição 2025/8/12 enviada em s3://dados-gabriel-espanhol/raw/2025/08/12/data.parquet\n",
      "Partição 2025/8/13 enviada em s3://dados-gabriel-espanhol/raw/2025/08/13/data.parquet\n",
      "Partição 2025/8/14 enviada em s3://dados-gabriel-espanhol/raw/2025/08/14/data.parquet\n",
      "Partição 2025/8/15 enviada em s3://dados-gabriel-espanhol/raw/2025/08/15/data.parquet\n",
      "Partição 2025/8/18 enviada em s3://dados-gabriel-espanhol/raw/2025/08/18/data.parquet\n",
      "Partição 2025/8/19 enviada em s3://dados-gabriel-espanhol/raw/2025/08/19/data.parquet\n",
      "Partição 2025/8/20 enviada em s3://dados-gabriel-espanhol/raw/2025/08/20/data.parquet\n",
      "Partição 2025/8/21 enviada em s3://dados-gabriel-espanhol/raw/2025/08/21/data.parquet\n",
      "Partição 2025/8/22 enviada em s3://dados-gabriel-espanhol/raw/2025/08/22/data.parquet\n",
      "Partição 2025/8/25 enviada em s3://dados-gabriel-espanhol/raw/2025/08/25/data.parquet\n",
      "Partição 2025/8/26 enviada em s3://dados-gabriel-espanhol/raw/2025/08/26/data.parquet\n",
      "Partição 2025/8/27 enviada em s3://dados-gabriel-espanhol/raw/2025/08/27/data.parquet\n",
      "Partição 2025/8/28 enviada em s3://dados-gabriel-espanhol/raw/2025/08/28/data.parquet\n",
      "Partição 2025/8/29 enviada em s3://dados-gabriel-espanhol/raw/2025/08/29/data.parquet\n",
      "Partição 2025/9/2 enviada em s3://dados-gabriel-espanhol/raw/2025/09/02/data.parquet\n",
      "Partição 2025/9/3 enviada em s3://dados-gabriel-espanhol/raw/2025/09/03/data.parquet\n",
      "Partição 2025/9/4 enviada em s3://dados-gabriel-espanhol/raw/2025/09/04/data.parquet\n",
      "Partição 2025/9/5 enviada em s3://dados-gabriel-espanhol/raw/2025/09/05/data.parquet\n",
      "Partição 2025/9/8 enviada em s3://dados-gabriel-espanhol/raw/2025/09/08/data.parquet\n",
      "Partição 2025/9/9 enviada em s3://dados-gabriel-espanhol/raw/2025/09/09/data.parquet\n",
      "Partição 2025/9/10 enviada em s3://dados-gabriel-espanhol/raw/2025/09/10/data.parquet\n",
      "Partição 2025/9/11 enviada em s3://dados-gabriel-espanhol/raw/2025/09/11/data.parquet\n",
      "Partição 2025/9/12 enviada em s3://dados-gabriel-espanhol/raw/2025/09/12/data.parquet\n",
      "Partição 2025/9/15 enviada em s3://dados-gabriel-espanhol/raw/2025/09/15/data.parquet\n",
      "Partição 2025/9/16 enviada em s3://dados-gabriel-espanhol/raw/2025/09/16/data.parquet\n",
      "Partição 2025/9/17 enviada em s3://dados-gabriel-espanhol/raw/2025/09/17/data.parquet\n",
      "Partição 2025/9/18 enviada em s3://dados-gabriel-espanhol/raw/2025/09/18/data.parquet\n",
      "Partição 2025/9/19 enviada em s3://dados-gabriel-espanhol/raw/2025/09/19/data.parquet\n",
      "Partição 2025/9/22 enviada em s3://dados-gabriel-espanhol/raw/2025/09/22/data.parquet\n",
      "Partição 2025/9/23 enviada em s3://dados-gabriel-espanhol/raw/2025/09/23/data.parquet\n",
      "Partição 2025/9/24 enviada em s3://dados-gabriel-espanhol/raw/2025/09/24/data.parquet\n",
      "Partição 2025/9/25 enviada em s3://dados-gabriel-espanhol/raw/2025/09/25/data.parquet\n",
      "Partição 2025/9/26 enviada em s3://dados-gabriel-espanhol/raw/2025/09/26/data.parquet\n",
      "Partição 2025/9/29 enviada em s3://dados-gabriel-espanhol/raw/2025/09/29/data.parquet\n",
      "Partição 2025/9/30 enviada em s3://dados-gabriel-espanhol/raw/2025/09/30/data.parquet\n",
      "Partição 2025/10/1 enviada em s3://dados-gabriel-espanhol/raw/2025/10/01/data.parquet\n",
      "Partição 2025/10/2 enviada em s3://dados-gabriel-espanhol/raw/2025/10/02/data.parquet\n",
      "Partição 2025/10/3 enviada em s3://dados-gabriel-espanhol/raw/2025/10/03/data.parquet\n"
     ]
    }
   ],
   "source": [
    "# Suponha que df_final já tenha a coluna 'Date'\n",
    "df_final['Date'] = pd.to_datetime(df_final['Date'])\n",
    "df_final['ano'] = df_final['Date'].dt.year\n",
    "df_final['mes'] = df_final['Date'].dt.month\n",
    "df_final['dia'] = df_final['Date'].dt.day\n",
    "\n",
    "s3_path = \"s3://dados-gabriel-espanhol/raw/\"\n",
    "\n",
    "# Iterar sobre cada partição\n",
    "for (ano, mes, dia), df_part in df_final.groupby([\"ano\", \"mes\", \"dia\"]):\n",
    "    # Caminho no formato que você pediu\n",
    "    path_part = f\"{s3_path}{ano}/{mes:02d}/{dia:02d}/data.parquet\"\n",
    "\n",
    "    # escreve só aquela partição (sem mode!)\n",
    "    wr.s3.to_parquet(\n",
    "        df=df_part,\n",
    "        path=path_part,\n",
    "        dataset=False  # salva como arquivo simples\n",
    "    )\n",
    "  \n",
    "    print(f\"Partição {ano}/{mes}/{dia} enviada em {path_part}\")\n",
    "    # time.sleep(5)  # delay entre as partições\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b9ee00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Arquivo enviado direto da memória para s3://dados-gabriel-espanhol/start_job.txt\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "bucket = \"dados-gabriel-espanhol\"\n",
    "chave = \"start_job.txt\"\n",
    "\n",
    "conteudo = \"start glue job\"\n",
    "\n",
    "# Upload a partir de string\n",
    "s3.put_object(Bucket=bucket, Key=chave, Body=conteudo.encode(\"utf-8\"))\n",
    "\n",
    "print(f\"Envia o arquivo para s3://{bucket}/{chave}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvboto3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
